# Backup and Disaster Recovery Systems for Global Scale

## Executive Summary

This document outlines the comprehensive backup and disaster recovery architecture designed to ensure business continuity and data protection for the Voltage Soda Platform's global operations with enterprise-grade recovery capabilities, automated failover, and multi-region data protection strategies.

## Disaster Recovery Architecture Overview

### Recovery Objectives Framework
```
Disaster Recovery Framework:
â”œâ”€â”€ Recovery Time Objectives (RTO)
â”‚   â”œâ”€â”€ Critical Services: <15 minutes
â”‚   â”œâ”€â”€ Important Services: <1 hour
â”‚   â”œâ”€â”€ Standard Services: <4 hours
â”‚   â””â”€â”€ Non-Critical Services: <24 hours
â”‚
â”œâ”€â”€ Recovery Point Objectives (RPO)
â”‚   â”œâ”€â”€ Database: <5 minutes (real-time replication)
â”‚   â”œâ”€â”€ File Storage: <1 hour (automated backup)
â”‚   â”œâ”€â”€ Configuration: <24 hours (versioned IaC)
â”‚   â””â”€â”€ Analytics: <4 hours (daily snapshots)
â”‚
â”œâ”€â”€ Service Level Agreements (SLA)
â”‚   â”œâ”€â”€ Uptime: 99.99% (52.56 minutes/year downtime)
â”‚   â”œâ”€â”€ Data Durability: 99.999999999% (11 9's)
â”‚   â”œâ”€â”€ Backup Success Rate: 99.9%
â”‚   â””â”€â”€ Recovery Success Rate: 99.95%
â”‚
â””â”€â”€ Business Continuity
    â”œâ”€â”€ Multi-Region Failover
    â”œâ”€â”€ Automated Recovery Procedures
    â”œâ”€â”€ Data Protection and Encryption
    â””â”€â”€ Compliance and Audit Requirements
```

### Multi-Region Backup Strategy

#### AWS Backup Configuration
```hcl
# AWS Backup configuration for global data protection
resource "aws_backup_plan" "voltage_soda_backup_plan" {
  name = "voltage-soda-global-backup-plan"
  
  rule {
    name             = "daily-backup"
    schedule         = "cron(0 2 * * ? *)"
    target_vault_name = aws_backup_vault.voltage_soda_vault.name
    start_window     = 60
    completion_window = 180
    copy_action {
      lifecycle {
        cold_storage_after = 7
        delete_after       = 365
      }
      destination_vault_arn = aws_backup_vault.voltage_soda_cross_region_vault.arn
    }
    lifecycle {
      cold_storage_after = 30
      delete_after       = 2555 # 7 years
    }
    recovery_point_tags = {
      Environment = "production"
      Project     = "voltage-soda"
      ManagedBy   = "aws-backup"
    }
  }
  
  rule {
    name             = "hourly-backup"
    schedule         = "cron(0 * * * ? *)"
    target_vault_name = aws_backup_vault.voltage_soda_vault.name
    start_window     = 30
    completion_window = 120
    lifecycle {
      cold_storage_after = 0
      delete_after       = 30
    }
    recovery_point_tags = {
      Frequency = "hourly"
      Environment = "production"
    }
  }
}

resource "aws_backup_selection" "voltage_soda_backup_selection" {
  iam_role_arn = aws_iam_role.backup_role.arn
  name         = "voltage-soda-backup-selection"
  plan_id      = aws_backup_plan.voltage_soda_backup_plan.id
  
  resources = [
    # RDS clusters
    aws_db_cluster.primary.arn,
    aws_db_cluster.eu_primary.arn,
    aws_db_cluster.apac_primary.arn,
    
    # DynamoDB tables
    aws_dynamodb_table.user_data.arn,
    aws_dynamodb_table.session_data.arn,
    aws_dynamodb_table.analytics_data.arn,
    
    # EFS file systems
    aws_efs_file_system.app_data.arn,
    
    # EBS volumes
    aws_ebs_volume.kubernetes_nodes.arn,
    
    # S3 buckets
    aws_s3_bucket.app_assets.arn,
    aws_s3_bucket.database_backups.arn,
    aws_s3_bucket.logs_archive.arn,
  ]
  
  condition {
    string_equals {
      key   = "aws:ResourceTag/BackupEnabled"
      value = "true"
    }
  }
}

resource "aws_backup_vault" "voltage_soda_vault" {
  name        = "voltage-soda-backup-vault"
  description = "Primary backup vault for Voltage Soda Platform"
  
  kms_key_arn = aws_kms_key.backup_encryption.arn
  
  tags = {
    Environment = "production"
    Project     = "voltage-soda"
    ManagedBy   = "terraform"
  }
}

resource "aws_backup_vault" "voltage_soda_cross_region_vault" {
  provider    = aws.us_west
  name        = "voltage-soda-backup-vault-us-west"
  description = "Cross-region backup vault for Voltage Soda Platform"
  
  kms_key_arn = aws_kms_key.backup_encryption_us_west.arn
  
  tags = {
    Environment = "production"
    Project     = "voltage-soda"
    Region      = "us-west-2"
    ManagedBy   = "terraform"
  }
}
```

#### Cross-Region Replication Configuration
```yaml
# Cross-region database replication
apiVersion: v1
kind: ConfigMap
metadata:
  name: cross-region-replication-config
  namespace: voltage-soda-database
data:
  replication-config.yaml: |
    # Primary region: us-east-1
    primary:
      region: us-east-1
      cluster_identifier: voltage-soda-primary
      database: voltage_soda
      username: replication_user
      password: ${REPLICATION_PASSWORD}
      max_lag: 5 seconds
      auto_promotion: true
    
    # Secondary regions for failover
    secondaries:
      - region: us-west-2
        cluster_identifier: voltage-soda-us-west-replica
        priority: 1
        auto_promotion: false
        lag_threshold: 30 seconds
      
      - region: eu-west-1
        cluster_identifier: voltage-soda-eu-replica
        priority: 2
        auto_promotion: false
        lag_threshold: 60 seconds
      
      - region: ap-southeast-1
        cluster_identifier: voltage-soda-apac-replica
        priority: 3
        auto_promotion: false
        lag_threshold: 120 seconds
    
    # Replication settings
    settings:
      synchronous_commit: local
      wal_level: replica
      max_wal_senders: 10
      max_replication_slots: 10
      shared_preload_libraries: "pg_stat_statements"
      track_activities: true
      track_counts: true
      track_io_timing: true
      track_functions: all
    
    # Monitoring
    monitoring:
      health_check_interval: 30s
      lag_threshold: 30s
      connection_timeout: 10s
      retry_attempts: 3
      alert_webhook: "https://alerts.voltage-soda.com/webhooks/replication"
```

### Database Disaster Recovery

#### Automated Database Failover
```sql
-- PostgreSQL automated failover procedure
CREATE OR REPLACE FUNCTION automated_failover()
RETURNS void AS $$
DECLARE
    current_lag INTERVAL;
    failover_needed BOOLEAN := FALSE;
    new_primary_region TEXT;
    failover_timestamp TIMESTAMP WITH TIME ZONE;
BEGIN
    failover_timestamp := NOW();
    
    -- Check replication lag
    SELECT EXTRACT(EPOCH FROM (NOW() - pg_last_xact_replay_timestamp()))::INTERVAL
    INTO current_lag;
    
    -- Determine if failover is needed
    IF current_lag > '30 seconds'::INTERVAL THEN
        failover_needed := TRUE;
        RAISE NOTICE 'Replication lag detected: %', current_lag;
    END IF;
    
    -- Check if primary is unreachable
    BEGIN
        PERFORM 1 FROM pg_database WHERE datname = current_database();
        IF NOT FOUND THEN
            failover_needed := TRUE;
            RAISE NOTICE 'Primary database unreachable';
        END IF;
    EXCEPTION
        WHEN OTHERS THEN
            failover_needed := TRUE;
            RAISE NOTICE 'Primary database connection failed';
    END;
    
    -- Execute failover if needed
    IF failover_needed THEN
        -- Log failover attempt
        INSERT INTO failover_log (
            failover_timestamp,
            trigger_reason,
            old_primary_region,
            new_primary_region,
            status
        ) VALUES (
            failover_timestamp,
            CASE 
                WHEN current_lag > '30 seconds'::INTERVAL THEN 'replication_lag'
                ELSE 'primary_unreachable'
            END,
            current_setting('app.current_region'),
            'pending',
            'initiated'
        );
        
        -- Attempt to promote read replica
        PERFORM pg_promote();
        
        -- Update DNS records (application would handle this)
        PERFORM pg_notify('dns_update', 'update_primary_dns');
        
        -- Update failover log
        UPDATE failover_log 
        SET new_primary_region = current_setting('app.current_region'),
            status = 'completed',
            completion_time = NOW()
        WHERE failover_timestamp = failover_timestamp;
        
        RAISE NOTICE 'Automated failover completed successfully';
    ELSE
        RAISE NOTICE 'No failover needed, system healthy';
    END IF;
    
EXCEPTION
    WHEN OTHERS THEN
        -- Log failover failure
        INSERT INTO failover_log (
            failover_timestamp,
            trigger_reason,
            old_primary_region,
            new_primary_region,
            status,
            error_message
        ) VALUES (
            failover_timestamp,
            CASE 
                WHEN current_lag > '30 seconds'::INTERVAL THEN 'replication_lag'
                ELSE 'primary_unreachable'
            END,
            current_setting('app.current_region'),
            'failed',
            'failed',
            SQLERRM
        );
        
        -- Notify operations team
        PERFORM pg_notify('alert_ops_team', 'failover_failed');
        
        RAISE EXCEPTION 'Automated failover failed: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Schedule failover check
SELECT cron.schedule('failover-check', '*/30 * * * * *', $$SELECT automated_failover();$$);
```

#### Backup and Restore Procedures
```bash
#!/bin/bash
# Database backup and restore automation script

set -e

ENVIRONMENT="${1:-production}"
BACKUP_TYPE="${2:-full}" # full, incremental, differential
TARGET_REGION="${3:-us-west-2}"

echo "ðŸ”„ Starting database backup operation"
echo "Environment: $ENVIRONMENT"
echo "Backup Type: $BACKUP_TYPE"
echo "Target Region: $TARGET_REGION"

# Configuration
PRIMARY_CLUSTER="voltage-soda-$ENVIRONMENT-primary"
SECONDARY_CLUSTER="voltage-soda-$ENVIRONMENT-secondary"
BACKUP_PREFIX="voltage-soda-$ENVIRONMENT-$(date +%Y%m%d-%H%M%S)"
S3_BACKUP_BUCKET="voltage-soda-$ENVIRONMENT-database-backups"

# Function to create database snapshot
create_database_snapshot() {
    local cluster_identifier="$1"
    local snapshot_identifier="$2"
    
    echo "ðŸ“¸ Creating database snapshot: $snapshot_identifier"
    
    aws rds create-db-snapshot \
        --db-instance-identifier "$cluster_identifier" \
        --db-snapshot-identifier "$snapshot_identifier" \
        --tags \
            Key=Environment,Value="$ENVIRONMENT" \
            Key=BackupType,Value="$BACKUP_TYPE" \
            Key=CreatedBy,Value="automated-backup" \
            Key=ManagedBy,Value="voltage-soda-dr"
    
    echo "â³ Waiting for snapshot to complete..."
    aws rds wait db-snapshot-completed \
        --db-snapshot-identifier "$snapshot_identifier" \
        --region "$TARGET_REGION"
    
    echo "âœ… Snapshot created successfully"
}

# Function to copy snapshot cross-region
copy_snapshot_cross_region() {
    local source_snapshot="$1"
    local target_snapshot="$2"
    local source_region="$3"
    local target_region="$4"
    
    echo "ðŸŒ Copying snapshot to $target_region..."
    
    aws rds copy-db-snapshot \
        --source-db-snapshot-identifier "$source_snapshot" \
        --target-db-snapshot-identifier "$target_snapshot" \
        --source-region "$source_region" \
        --region "$target_region" \
        --copy-tags \
        --tag-specifications \
            ResourceType=db-snapshot,Tags=Key=Environment,Value="$ENVIRONMENT"
    
    echo "â³ Waiting for cross-region copy to complete..."
    aws rds wait db-snapshot-completed \
        --db-snapshot-identifier "$target_snapshot" \
        --region "$target_region"
    
    echo "âœ… Cross-region copy completed"
}

# Function to upload to S3
upload_to_s3() {
    local snapshot_identifier="$1"
    local target_region="$2"
    
    echo "ðŸ“¤ Uploading backup to S3..."
    
    # Download snapshot
    local download_path="/tmp/$snapshot_identifier.sql"
    aws rds download-db-snapshot \
        --db-snapshot-identifier "$snapshot_identifier" \
        --region "$target_region" \
        --output-file "$download_path"
    
    # Upload to S3
    aws s3 cp "$download_path" \
        "s3://$S3_BACKUP_BUCKET/$ENVIRONMENT/$BACKUP_TYPE/$snapshot_identifier.sql" \
        --region "$target_region"
    
    # Clean up local file
    rm -f "$download_path"
    
    echo "âœ… Backup uploaded to S3 successfully"
}

# Function to validate backup
validate_backup() {
    local backup_identifier="$1"
    local target_region="$2"
    
    echo "ðŸ” Validating backup integrity..."
    
    # Check S3 object exists and has content
    local s3_key="$ENVIRONMENT/$BACKUP_TYPE/$backup_identifier.sql"
    local s3_size=$(aws s3api head-object \
        --bucket "$S3_BACKUP_BUCKET" \
        --key "$s3_key" \
        --region "$target_region" \
        --query 'ContentLength' \
        --output text)
    
    if [ "$s3_size" -gt 0 ]; then
        echo "âœ… Backup validation passed (size: $s3_size bytes)"
        return 0
    else
        echo "âŒ Backup validation failed (empty or missing)"
        return 1
    fi
}

# Function to create test restore
create_test_restore() {
    local backup_identifier="$1"
    local test_instance_name="voltage-soda-$ENVIRONMENT-restore-test-$(date +%s)"
    local target_region="$2"
    
    echo "ðŸ§ª Creating test restore instance: $test_instance_name"
    
    # Create test instance from backup
    aws rds restore-db-instance-from-db-snapshot \
        --db-instance-identifier "$test_instance_name" \
        --db-snapshot-identifier "$backup_identifier" \
        --db-instance-class db.r6g.large \
        --region "$target_region" \
        --storage-encrypted \
        --enable-iam-database-authentication \
        --tags \
            Key=Environment,Value="$ENVIRONMENT" \
            Key=Purpose,Value="restore-test" \
            Key=ManagedBy,Value="voltage-soda-dr"
    
    echo "â³ Waiting for test instance to be available..."
    aws rds wait db-instance-available \
        --db-instance-identifier "$test_instance_name" \
        --region "$target_region"
    
    # Perform basic validation
    echo "ðŸ§ª Testing database connectivity..."
    local endpoint=$(aws rds describe-db-instances \
        --db-instance-identifier "$test_instance_name" \
        --region "$target_region" \
        --query 'DBInstances[0].Endpoint.Address' \
        --output text)
    
    # Test basic connectivity
    if PGPASSWORD="$TEST_PASSWORD" psql -h "$endpoint" -U "$TEST_USERNAME" -d postgres -c "SELECT version();" > /dev/null 2>&1; then
        echo "âœ… Test restore validation passed"
        
        # Clean up test instance
        echo "ðŸ§¹ Cleaning up test instance..."
        aws rds delete-db-instance \
            --db-instance-identifier "$test_instance_name" \
            --skip-final-snapshot \
            --region "$target_region"
        
        return 0
    else
        echo "âŒ Test restore validation failed"
        return 1
    fi
}

# Function to notify completion
notify_completion() {
    local status="$1"
    local details="$2"
    
    echo "ðŸ“¢ Notifying completion..."
    
    # Send notification to monitoring system
    curl -X POST "$ALERT_WEBHOOK" \
        -H 'Content-type: application/json' \
        -d "{
            \"status\": \"$status\",
            \"service\": \"database-backup\",
            \"environment\": \"$ENVIRONMENT\",
            \"backup_type\": \"$BACKUP_TYPE\",
            \"details\": \"$details\",
            \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"
        }"
}

# Main backup execution
main() {
    local backup_timestamp=$(date +%Y%m%d-%H%M%S)
    local backup_identifier="$BACKUP_PREFIX"
    
    echo "ðŸš€ Starting $BACKUP_TYPE backup for $ENVIRONMENT"
    
    # Create primary snapshot
    create_database_snapshot "$PRIMARY_CLUSTER" "$backup_identifier"
    
    # Copy to target region
    if [ "$TARGET_REGION" != "us-east-1" ]; then
        copy_snapshot_cross_region \
            "arn:aws:rds:us-east-1:$ACCOUNT_ID:snapshot:$backup_identifier" \
            "$backup_identifier-$TARGET_REGION" \
            "us-east-1" \
            "$TARGET_REGION"
        
        backup_identifier="$backup_identifier-$TARGET_REGION"
    fi
    
    # Upload to S3
    upload_to_s3 "$backup_identifier" "$TARGET_REGION"
    
    # Validate backup
    if validate_backup "$backup_identifier" "$TARGET_REGION"; then
        # Create test restore for full backups
        if [ "$BACKUP_TYPE" = "full" ]; then
            create_test_restore "$backup_identifier" "$TARGET_REGION"
        fi
        
        notify_completion "success" "Backup completed successfully: $backup_identifier"
        echo "âœ… Database backup completed successfully"
    else
        notify_completion "failed" "Backup validation failed: $backup_identifier"
        echo "âŒ Database backup failed validation"
        exit 1
    fi
}

# Execute main function
main "$@"
```

### Application-Level Disaster Recovery

#### Kubernetes Cluster Backup
```yaml
# Velero backup configuration for Kubernetes resources
apiVersion: v1
kind: ConfigMap
metadata:
  name: velero-backup-config
  namespace: velero
data:
  backup-config.yaml: |
    # Velero backup schedule configuration
    schedules:
      daily-backup:
        schedule: "0 2 * * *"
        template:
          includedNamespaces:
          - voltage-soda
          - voltage-soda-monitoring
          - voltage-soda-security
          excludedNamespaces:
          - kube-system
          - kube-public
          includedResources:
          - persistentvolumeclaims
          - secrets
          - configmaps
          - deployments
          - services
          - ingresses
          excludedResources:
          - events
          - events.events.k8s.io
          - ingresses.networking.k8s.io
          labelSelector:
            matchLabels:
              backup-enabled: "true"
          storageLocation: voltage-soda-backup-location
          ttl: 720h # 30 days
      
      hourly-backup:
        schedule: "0 * * * *"
        template:
          includedNamespaces:
          - voltage-soda
          includedResources:
          - secrets
          - configmaps
          storageLocation: voltage-soda-backup-location
          ttl: 168h # 7 days
      
      weekly-backup:
        schedule: "0 6 * * 0"
        template:
          includedNamespaces:
          - voltage-soda
          - voltage-soda-monitoring
          - voltage-soda-security
          includedResources:
          - '*'
          storageLocation: voltage-soda-backup-location
          ttl: 2160h # 90 days

  restore-config.yaml: |
    # Velero restore configuration
    defaultRestoreOptions:
      waitForCompletion: true
      restorePVs: true
      preserveNodePorts: true
    
    restoreHooks:
      postRestore:
      - name: update-dns-records
        exec:
          command:
          - /scripts/update-dns-after-restore.sh
          timeout: 300s
      
      - name: update-istio-configuration
        exec:
          command:
          - /scripts/update-istio-after-restore.sh
          timeout: 300s
```

#### Service Mesh Backup and Recovery
```bash
#!/bin/bash
# Istio configuration backup and restore script

set -e

OPERATION="${1:-backup}" # backup, restore, validate
CLUSTER_NAME="${2:-voltage-soda-primary}"
BACKUP_DIR="${3:-/backups/istio}"

echo "ðŸ”§ Istio Configuration $OPERATION for cluster: $CLUSTER_NAME"

# Backup Istio configuration
backup_istio_config() {
    echo "ðŸ“¦ Backing up Istio configuration..."
    
    mkdir -p "$BACKUP_DIR/istio"
    cd "$BACKUP_DIR/istio"
    
    # Backup custom resources
    kubectl get destinationrules -o yaml > destination-rules.yaml
    kubectl get virtualservices -o yaml > virtual-services.yaml
    kubectl get gateways -o yaml > gateways.yaml
    kubectl get serviceentries -o yaml > service-entries.yaml
    kubectl get authorizationpolicies -o yaml > authorization-policies.yaml
    kubectl get peerauthentications -o yaml > peer-authentications.yaml
    kubectl get requestauthentications -o yaml > request-authentications.yaml
    kubectl get telemetry -o yaml > telemetry.yaml
    
    # Backup Istio operator configuration
    kubectl get istiooperator -o yaml > istio-operator-config.yaml
    
    # Backup ingress gateway configuration
    kubectl get svc istio-ingressgateway -n istio-system -o yaml > ingress-gateway.yaml
    kubectl get svc istio-egressgateway -n istio-system -o yaml > egress-gateway.yaml
    
    # Create compressed archive
    tar -czf "istio-backup-$(date +%Y%m%d-%H%M%S).tar.gz" *.yaml
    
    echo "âœ… Istio configuration backed up successfully"
}

# Restore Istio configuration
restore_istio_config() {
    echo "ðŸ”„ Restoring Istio configuration..."
    
    cd "$BACKUP_DIR/istio"
    
    # Find latest backup
    LATEST_BACKUP=$(ls -t istio-backup-*.tar.gz | head -1)
    
    if [ -z "$LATEST_BACKUP" ]; then
        echo "âŒ No Istio backup found"
        exit 1
    fi
    
    echo "ðŸ“¦ Extracting backup: $LATEST_BACKUP"
    tar -xzf "$LATEST_BACKUP"
    
    # Wait for Istio system to be ready
    echo "â³ Waiting for Istio system to be ready..."
    kubectl wait --for=condition=ready pod -l app=istiod -n istio-system --timeout=300s
    
    # Restore configuration in order
    echo "ðŸ”„ Restoring Istio configuration..."
    
    # Peer authentication (mTLS)
    if [ -f peer-authentications.yaml ]; then
        echo "ðŸ”’ Restoring peer authentication..."
        kubectl apply -f peer-authentications.yaml
        sleep 10
    fi
    
    # Request authentication (JWT)
    if [ -f request-authentications.yaml ]; then
        echo "ðŸ”‘ Restoring request authentication..."
        kubectl apply -f request-authentications.yaml
        sleep 10
    fi
    
    # Authorization policies
    if [ -f authorization-policies.yaml ]; then
        echo "ðŸ›¡ï¸  Restoring authorization policies..."
        kubectl apply -f authorization-policies.yaml
        sleep 10
    fi
    
    # Destination rules
    if [ -f destination-rules.yaml ]; then
        echo "ðŸŽ¯ Restoring destination rules..."
        kubectl apply -f destination-rules.yaml
        sleep 10
    fi
    
    # Virtual services
    if [ -f virtual-services.yaml ]; then
        echo "ðŸ›£ï¸  Restoring virtual services..."
        kubectl apply -f virtual-services.yaml
        sleep 10
    fi
    
    # Gateways
    if [ -f gateways.yaml ]; then
        echo "ðŸšª Restoring gateways..."
        kubectl apply -f gateways.yaml
        sleep 10
    fi
    
    # Service entries
    if [ -f service-entries.yaml ]; then
        echo "ðŸŒ Restoring service entries..."
        kubectl apply -f service-entries.yaml
        sleep 10
    fi
    
    # Telemetry
    if [ -f telemetry.yaml ]; then
        echo "ðŸ“Š Restoring telemetry configuration..."
        kubectl apply -f telemetry.yaml
        sleep 10
    fi
    
    echo "âœ… Istio configuration restored successfully"
}

# Validate Istio configuration
validate_istio_config() {
    echo "ðŸ” Validating Istio configuration..."
    
    # Check Istio system pods
    kubectl get pods -n istio-system
    
    # Check mTLS status
    echo "ðŸ”’ Checking mTLS status..."
    kubectl exec -n istio-system deployment/istiod -- pilot-agent request GET /debug/configz
    
    # Check proxy configuration
    echo "ðŸ” Checking proxy configuration..."
    kubectl get pods -n voltage-soda | head -5 | while read pod_name; do
        echo "Checking proxy config for $pod_name..."
        kubectl exec -n voltage-soda "$pod_name" -c istio-proxy -- pilot-agent request GET /debug/configz || true
    done
    
    # Test service connectivity
    echo "ðŸŒ Testing service connectivity..."
    kubectl run test-connectivity --image=curlimages/curl --rm -it --restart=Never -- \
        curl -m 5 http://voltage-soda-backend.voltage-soda.svc.cluster.local:8080/health || true
    
    echo "âœ… Istio configuration validation completed"
}

# Main execution
case "$OPERATION" in
    "backup")
        backup_istio_config
        ;;
    "restore")
        restore_istio_config
        ;;
    "validate")
        validate_istio_config
        ;;
    *)
        echo "Usage: $0 {backup|restore|validate} [cluster-name] [backup-dir]"
        exit 1
        ;;
esac
```

### Multi-Cloud Disaster Recovery

#### Azure Site Recovery Configuration
```json
{
  "vault": {
    "name": "voltage-soda-dr-vault",
    "resource_group": "voltage-soda-dr-rg",
    "location": "eastus2",
    "sku": "Standard"
  },
  "replication_policies": {
    "vm_replication_policy": {
      "name": "voltage-soda-vm-policy",
      "recovery_point_retention": {
        "min": 2880,
        "max": 43200
      },
      "application_consistent_snapshot_frequency": "60",
      "compression": "Enabled",
      "replication_scheduled_frequency": "15"
    }
  },
  "container_mapping": {
    "name": "voltage-soda-container-mapping",
    "source_container": "voltage-soda-prod",
    "target_container": "voltage-soda-dr",
    "target_vault": "voltage-soda-dr-vault",
    "replication_policy": "voltage-soda-vm-policy"
  },
  "vm_replication": {
    "virtual_machines": [
      {
        "name": "voltage-soda-frontend-vm",
        "resource_group": "voltage-soda-prod-rg",
        "vault": "voltage-soda-dr-vault",
        "policy": "voltage-soda-vm-policy",
        "source_container": "voltage-soda-prod",
        "target_vnet": "voltage-soda-dr-vnet",
        "target_subnet": "voltage-soda-dr-subnet",
        "target_resource_group": "voltage-soda-dr-rg",
        "target_region": "westus2",
        "recovery_vnet": "voltage-soda-dr-vnet",
        "recovery_subnet": "voltage-soda-dr-subnet",
        "replication_scheduled_frequency": "15",
        "application_consistent_snapshot_frequency": "60"
      }
    ]
  }
}
```

#### Google Cloud Disaster Recovery
```yaml
# Google Cloud Build configuration for DR
steps:
  # Create point-in-time backup
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'sql'
      - 'backups'
      - 'create'
      - '--instance=voltage-soda-primary'
      - '--description=DR-backup-$(date +%Y%m%d-%H%M%S)'
      - '--async'
  
  # Export data to Cloud Storage
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'sql'
      - 'export'
      - 'sql'
      - 'voltage-soda-primary'
      - 'gs://voltage-soda-dr-backups/$(date +%Y%m%d)/database.sql'
      - '--offload'
  
  # Create disk snapshots
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'compute'
      - 'disks'
      - 'snapshot'
      - 'voltage-soda-disk-1'
      - '--snapshot-names=voltage-soda-snapshot-$(date +%Y%m%d-%H%M%S)'
      - '--description=DR snapshot for Voltage Soda'
      - '--storage-location=us-west2'
  
  # Replicate to secondary region
  - name: 'gcr.io/cloud-builders/gsutil'
    args:
      - 'cp'
      - '-r'
      - 'gs://voltage-soda-dr-backups/$(date +%Y%m%d)'
      - 'gs://voltage-soda-dr-backups-us-west2/$(date +%Y%m%d)'
  
  # Update DNS records
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'dns'
      - 'record-sets'
      - 'update'
      - '--zone=voltage-soda-zone'
      - '--name=api.voltage-soda.com'
      - '--type=CNAME'
      - '--ttl=300'
      - '--cname=api-dr.voltage-soda.com'
  
  # Notify completion
  - name: 'gcr.io/cloud-builders/gcloud'
    args:
      - 'pubsub'
      - 'topics'
      - 'publish'
      - 'voltage-soda-dr-events'
      - '--message={"event":"backup_completed","timestamp":"$(date -u +%Y-%m-%dT%H:%M:%SZ)","status":"success"}'
```

### Disaster Recovery Testing

#### Automated DR Testing Framework
```python
#!/usr/bin/env python3
"""
Disaster Recovery Testing Framework
Comprehensive testing of backup and recovery procedures
"""

import asyncio
import boto3
import json
import time
import subprocess
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class TestResult:
    test_name: str
    status: str  # PASS, FAIL, WARNING
    duration: float
    details: str
    timestamp: datetime

class DisasterRecoveryTester:
    def __init__(self, config: Dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.results: List[TestResult] = []
        
        # Initialize AWS clients
        self.rds = boto3.client('rds', region_name=config['aws_region'])
        self.s3 = boto3.client('s3', region_name=config['aws_region'])
        self.ec2 = boto3.client('ec2', region_name=config['aws_region'])
        self.dynamodb = boto3.client('dynamodb', region_name=config['aws_region'])
    
    async def run_all_tests(self) -> Dict:
        """Run all disaster recovery tests"""
        test_methods = [
            self.test_database_backup_integrity,
            self.test_cross_region_replication,
            self.test_failover_procedure,
            self.test_application_recovery,
            self.test_data_consistency,
            self.test_backup_restore_cycle,
            self.test_dns_failover,
            self.test_kubernetes_recovery,
            self.test_monitoring_alerts,
            self.test_documentation_availability
        ]
        
        for test_method in test_methods:
            try:
                await test_method()
            except Exception as e:
                self.logger.error(f"Test {test_method.__name__} failed: {str(e)}")
                self.results.append(TestResult(
                    test_name=test_method.__name__,
                    status='FAIL',
                    duration=0,
                    details=str(e),
                    timestamp=datetime.utcnow()
                ))
        
        return self.generate_test_report()
    
    async def test_database_backup_integrity(self):
        """Test database backup integrity"""
        test_name = "database_backup_integrity"
        start_time = time.time()
        
        try:
            # Get latest backup
            backups = self.rds.describe_db_snapshots(
                DBInstanceIdentifier=self.config['primary_db_instance'],
                MaxRecords=20
            )['DBSnapshots']
            
            if not backups:
                raise Exception("No database backups found")
            
            latest_backup = max(backups, key=lambda x: x['SnapshotCreateTime'])
            
            # Verify backup status
            if latest_backup['Status'] != 'available':
                raise Exception(f"Latest backup status is {latest_backup['Status']}")
            
            # Check backup age
            backup_age = datetime.utcnow() - latest_backup['SnapshotCreateTime']
            if backup_age > timedelta(hours=24):
                raise Exception(f"Latest backup is {backup_age} old, exceeds 24 hours")
            
            # Verify backup size
            if latest_backup['AllocatedStorage'] < 100:  # At least 100GB
                raise Exception("Backup size seems too small")
            
            duration = time.time() - start_time
            self.results.append(TestResult(
                test_name=test_name,
                status='PASS',
                duration=duration,
                details=f"Latest backup from {latest_backup['SnapshotCreateTime']} is valid",
                timestamp=datetime.utcnow()
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.results.append(TestResult(
                test_name=test_name,
                status='FAIL',
                duration=duration,
                details=str(e),
                timestamp=datetime.utcnow()
            ))
    
    async def test_cross_region_replication(self):
        """Test cross-region replication health"""
        test_name = "cross_region_replication"
        start_time = time.time()
        
        try:
            # Check replication lag for each read replica
            for region, config in self.config['replication_regions'].items():
                try:
                    # Get replica status
                    replicas = self.rds.describe_db_instances(
                        Filters=[
                            {
                                'Name': 'db-cluster-id',
                                'Values': [config['cluster_id']]
                            }
                        ]
                    )['DBInstances']
                    
                    for replica in replicas:
                        # Check if it's a read replica
                        if replica.get('ReadReplicaSourceDBInstanceIdentifier'):
                            source_id = replica['ReadReplicaSourceDBInstanceIdentifier']
                            
                            # Get source instance info
                            source_instance = self.rds.describe_db_instances(
                                DBInstanceIdentifier=source_id
                            )['DBInstances'][0]
                            
                            # Check replication status
                            if replica['DBInstanceStatus'] != 'available':
                                raise Exception(f"Replica {replica['DBInstanceIdentifier']} is not available")
                            
                            # Check connection
                            endpoint = replica['Endpoint']['Address']
                            # Here you would test actual connectivity
                            
                            self.logger.info(f"Replica {replica['DBInstanceIdentifier']} in {region} is healthy")
                
                except Exception as e:
                    self.logger.warning(f"Replica check failed for {region}: {str(e)}")
            
            duration = time.time() - start_time
            self.results.append(TestResult(
                test_name=test_name,
                status='PASS',
                duration=duration,
                details="Cross-region replication is healthy",
                timestamp=datetime.utcnow()
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.results.append(TestResult(
                test_name=test_name,
                status='FAIL',
                duration=duration,
                details=str(e),
                timestamp=datetime.utcnow()
            ))
    
    async def test_failover_procedure(self):
        """Test automated failover procedure"""
        test_name = "automated_failover"
        start_time = time.time()
        
        try:
            # Simulate failover test (do not actually perform failover)
            # Instead, validate that failover procedures are configured
            
            # Check if automated failover is enabled
            db_cluster = self.rds.describe_db_clusters(
                DBClusterIdentifier=self.config['primary_cluster_id']
            )['DBClusters'][0]
            
            if not db_cluster.get('AutomaticFailover'):
                raise Exception("Automatic failover is not enabled")
            
            # Check failover priority
            if not db_cluster.get('DBClusterParameterGroup'):
                raise Exception("Cluster parameter group not configured")
            
            # Check if read replicas have proper priority
            replicas = self.rds.describe_db_instances(
                Filters=[
                    {
                        'Name': 'db-cluster-id',
                        'Values': [self.config['primary_cluster_id']]
                    }
                ]
            )['DBInstances']
            
            for replica in replicas:
                if replica.get('PubliclyAccessible', True):
                    # This would be a read replica
                    self.logger.info(f"Read replica {replica['DBInstanceIdentifier']} configured")
            
            duration = time.time() - start_time
            self.results.append(TestResult(
                test_name=test_name,
                status='PASS',
                duration=duration,
                details="Failover procedures are properly configured",
                timestamp=datetime.utcnow()
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.results.append(TestResult(
                test_name=test_name,
                status='FAIL',
                duration=duration,
                details=str(e),
                timestamp=datetime.utcnow()
            ))
    
    async def test_application_recovery(self):
        """Test application recovery procedures"""
        test_name = "application_recovery"
        start_time = time.time()
        
        try:
            # Test Kubernetes cluster recovery
            # Check if backup and restore procedures exist
            
            # Validate Helm charts exist
            helm_charts = subprocess.run(
                ['helm', 'list', '-n', 'voltage-soda'],
                capture_output=True,
                text=True
            )
            
            if helm_charts.returncode != 0:
                raise Exception("Helm charts not accessible")
            
            # Check if application deployments are in good state
            kubectl_get = subprocess.run(
                ['kubectl', 'get', 'deployments', '-n', 'voltage-soda', '-o', 'json'],
                capture_output=True,
                text=True
            )
            
            if kubectl_get.returncode == 0:
                deployments = json.loads(kubectl_get.stdout)
                
                for deployment in deployments['items']:
                    ready_replicas = deployment['status'].get('readyReplicas', 0)
                    desired_replicas = deployment['spec']['replicas']
                    
                    if ready_replicas < desired_replicas:
                        raise Exception(f"Deployment {deployment['metadata']['name']} has {ready_replicas}/{desired_replicas} ready replicas")
            
            duration = time.time() - start_time
            self.results.append(TestResult(
                test_name=test_name,
                status='PASS',
                duration=duration,
                details="Application recovery procedures are valid",
                timestamp=datetime.utcnow()
            ))
            
        except Exception as e:
            duration = time.time() - start_time
            self.results.append(TestResult(
                test_name=test_name,
                status='FAIL',
                duration=duration,
                details=str(e),
                timestamp=datetime.utcnow()
            ))
    
    def generate_test_report(self) -> Dict:
        """Generate comprehensive test report"""
        total_tests = len(self.results)
        passed_tests = len([r for r in self.results if r.status == 'PASS'])
        failed_tests = len([r for r in self.results if r.status == 'FAIL'])
        warning_tests = len([r for r in self.results if r.status == 'WARNING'])
        
        total_duration = sum(r.duration for r in self.results)
        
        report = {
            'test_summary': {
                'total_tests': total_tests,
                'passed': passed_tests,
                'failed': failed_tests,
                'warnings': warning_tests,
                'success_rate': (passed_tests / total_tests * 100) if total_tests > 0 else 0,
                'total_duration': total_duration
            },
            'test_results': [
                {
                    'test_name': r.test_name,
                    'status': r.status,
                    'duration': r.duration,
                    'details': r.details,
                    'timestamp': r.timestamp.isoformat()
                }
                for r in self.results
            ],
            'recommendations': self.generate_recommendations(),
            'generated_at': datetime.utcnow().isoformat()
        }
        
        return report
    
    def generate_recommendations(self) -> List[str]:
        """Generate recommendations based on test results"""
        recommendations = []
        
        failed_tests = [r for r in self.results if r.status == 'FAIL']
        
        if any('backup' in r.test_name for r in failed_tests):
            recommendations.append("Review and update backup procedures")
        
        if any('replication' in r.test_name for r in failed_tests):
            recommendations.append("Check cross-region replication configuration")
        
        if any('failover' in r.test_name for r in failed_tests):
            recommendations.append("Validate automated failover procedures")
        
        if any('recovery' in r.test_name for r in failed_tests):
            recommendations.append("Test application recovery procedures")
        
        return recommendations

# Main execution
async def main():
    config = {
        'aws_region': 'us-east-1',
        'primary_cluster_id': 'voltage-soda-primary-cluster',
        'primary_db_instance': 'voltage-soda-primary',
        'replication_regions': {
            'us-west-2': {'cluster_id': 'voltage-soda-us-west-cluster'},
            'eu-west-1': {'cluster_id': 'voltage-soda-eu-cluster'},
            'ap-southeast-1': {'cluster_id': 'voltage-soda-apac-cluster'}
        }
    }
    
    tester = DisasterRecoveryTester(config)
    report = await tester.run_all_tests()
    
    # Save report
    with open(f'dr_test_report_{datetime.utcnow().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    print(f"DR Testing completed: {report['test_summary']['success_rate']:.1f}% success rate")
    
    return report

if __name__ == "__main__":
    asyncio.run(main())
```

### Monitoring and Alerting for DR

#### Backup Monitoring Dashboard
```yaml
# Prometheus alert rules for disaster recovery monitoring
groups:
  - name: disaster_recovery_alerts
    rules:
      # Backup failure alert
      - alert: BackupFailure
        expr: |
          (
            increase(voltage_soda_backup_failures_total[1h]) > 0
            or
            voltage_soda_backup_last_success_timestamp < (time() - 86400)
          )
        for: 5m
        labels:
          severity: critical
          service: disaster_recovery
        annotations:
          summary: "Database backup failure detected"
          description: "Last successful backup was {{ $value }} hours ago"
          runbook_url: "https://runbooks.voltage-soda.com/backup-failure"
      
      # Replication lag alert
      - alert: ReplicationLag
        expr: voltage_soda_replication_lag_seconds > 300
        for: 2m
        labels:
          severity: warning
          service: disaster_recovery
        annotations:
          summary: "Database replication lag detected"
          description: "Replication lag is {{ $value }} seconds"
          runbook_url: "https://runbooks.voltage-soda.com/replication-lag"
      
      # Failover test failure
      - alert: FailoverTestFailure
        expr: voltage_soda_failover_test_success_rate < 0.95
        for: 10m
        labels:
          severity: critical
          service: disaster_recovery
        annotations:
          summary: "Failover test failure rate is too high"
          description: "Failover test success rate is {{ $value | humanizePercentage }}"
          runbook_url: "https://runbooks.voltage-soda.com/failover-test"
      
      # RPO violation
      - alert: RPOViolation
        expr: voltage_soda_data_loss_rto_seconds > 300
        for: 1m
        labels:
          severity: critical
          service: disaster_recovery
        annotations:
          summary: "Recovery Point Objective (RPO) violated"
          description: "Potential data loss window is {{ $value }} seconds"
          runbook_url: "https://runbooks.voltage-soda.com/rpo-violation"
      
      # RTO violation
      - alert: RTOViolation
        expr: voltage_soda_recovery_time_seconds > 900
        for: 5m
        labels:
          severity: critical
          service: disaster_recovery
        annotations:
          summary: "Recovery Time Objective (RTO) violated"
          description: "Recovery time exceeded {{ $value }} seconds"
          runbook_url: "https://runbooks.voltage-soda.com/rto-violation"
```

## Implementation Timeline

### Phase 1 (Weeks 1-2): Foundation Setup
- [ ] Configure AWS Backup services
- [ ] Set up cross-region replication
- [ ] Implement automated backup procedures
- [ ] Configure monitoring and alerting

### Phase 2 (Weeks 3-4): Application Protection
- [ ] Implement Kubernetes backup with Velero
- [ ] Configure service mesh backup procedures
- [ ] Set up application-level data protection
- [ ] Implement testing framework

### Phase 3 (Weeks 5-6): Multi-Cloud DR
- [ ] Configure Azure Site Recovery
- [ ] Set up Google Cloud DR procedures
- [ ] Implement cross-cloud data replication
- [ ] Configure unified DR dashboard

### Phase 4 (Weeks 7-8): Testing and Validation
- [ ] Comprehensive DR testing
- [ ] Performance optimization
- [ ] Documentation and training
- [ ] Production readiness validation

## Success Metrics

### Backup Metrics
- **Backup Success Rate**: >99.9% automated backups
- **Backup Completion Time**: <4 hours for full backup
- **Backup Integrity**: 100% validation success
- **Cross-Region Replication**: <5 seconds lag

### Recovery Metrics
- **RTO Achievement**: <15 minutes for critical services
- **RPO Achievement**: <5 minutes data loss window
- **Recovery Success Rate**: >99.95% successful recoveries
- **Test Coverage**: 100% DR procedures tested quarterly

### Operational Metrics
- **Monitoring Coverage**: 100% backup and recovery monitoring
- **Alert Response Time**: <5 minutes for critical DR alerts
- **Documentation Accuracy**: 100% up-to-date procedures
- **Team Readiness**: 100% team DR training completion

This comprehensive backup and disaster recovery system ensures business continuity and data protection for global scale operations with enterprise-grade recovery capabilities.